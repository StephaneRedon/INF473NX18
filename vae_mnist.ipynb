{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "vae_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB45F4XMfD7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2jzc_0LfKsG",
        "colab_type": "code",
        "outputId": "698f052a-7f1c-4dbb-caae-5ed9c5075d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ1Cx0wvfD8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((\"/content/gdrive/My Drive/Colab Notebooks/Modal_VAE/mnist/mnist.pkl.gz\"), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3tjkjnefD8g",
        "colab_type": "code",
        "outputId": "19f4a688-5215-4ba2-952a-10bb363a1acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "print(x_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA1K0lpJfD8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC87YpVzfD8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "train_data = torch.tensor(x_train, device=dev).reshape(train_size, 28, 28).unsqueeze(1)\n",
        "train_target = torch.tensor(y_train, device=dev)\n",
        "\n",
        "valid_size = x_valid.shape[0]\n",
        "valid_data = torch.tensor(x_valid, device=dev).reshape(valid_size, 28, 28).unsqueeze(1)\n",
        "valid_target = torch.tensor(y_valid, device=dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fS_ZS8XfD85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1qTbNjTfD9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = TensorDataset(train_data, train_data)\n",
        "valid_ds = TensorDataset(valid_data, valid_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Omyyz20fD9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, 2*bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt6LtCPJfD9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, channels, dim_h, dim_z):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 1, (2,2), stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(1, 1, (2,2), stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(1, 1, (2,2), stride=1, padding=0),        \n",
        "        )\n",
        "        \n",
        "        self.p1 = nn.Linear(dim_h, dim_z)\n",
        "        self.p2 = nn.Linear(dim_h, dim_z)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ConvTranspose2d(1, 1, (2,2), stride=2, padding=0),            \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(1, 1, (3,3), stride=2, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(1, 1, (4,4), stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ConvTranspose2d(1, 1, (2,2), stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ConvTranspose2d(1, 1, (2,2), stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(1, 1, (3,3), stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ConvTranspose2d(1, 1, (3,3), stride=1, padding=0),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ConvTranspose2d(1, 1, (3,3), stride=1, padding=0)\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(1)\n",
        "        self.bn2 = nn.BatchNorm2d(1)\n",
        "    \n",
        "    def encode(self, in_data):\n",
        "        h = self.encoder(in_data)\n",
        "        h = h.reshape(h.shape[0], -1)\n",
        "\n",
        "        #mu = self.p1(h)\n",
        "        #log_var = self.p2(h)\n",
        "        h = self.p1(h)\n",
        "        mu, log_var = torch.split(h, 16, 1)\n",
        "        \n",
        "        #sampling and reparameterization for backprop\n",
        "        z = torch.rand(mu.shape, device = dev)\n",
        "        z = mu + torch.exp(log_var) * z\n",
        "        z = z.reshape(z.shape[0], 1, 4, 4)\n",
        "        return z, mu, log_var\n",
        "    \n",
        "    def decode(self, h_data):\n",
        "        z = self.decoder(h_data)\n",
        "        return z\n",
        "                \n",
        "    def forward(self, in_data):\n",
        "        z, mu, log_var = self.encode(in_data)\n",
        "\n",
        "        z = self.decode(z)\n",
        "        return z, mu, log_var        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRFpi7HvfD9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vae = VAE(11, 36, 32).to(dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ6YmOe9fD9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kullback–Leibler divergence for N(mu, var^2) and N(0, I)\n",
        "def kl_divergence(mu, log_var):\n",
        "    return 0.5*( torch.sum( log_var.exp(), 1) + torch.sum(mu*mu, 1) - mu.shape[1] - torch.sum(log_var, 1) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEV3BCH4fD9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(MSE loss + Kullback–Leibler divergence) / batch\n",
        "def vae_loss(mu, log_var, pred, target):\n",
        "    bs = pred.shape[0]\n",
        "    kl_loss = kl_divergence(mu, log_var).mean()\n",
        "    mse_loss = F.l1_loss(pred, target, reduction = 'sum') / bs\n",
        "    return (kl_loss + mse_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNlxNc-nfD9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riOO5T7tfD9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = vae_loss\n",
        "opt = torch.optim.Adam(model_vae.parameters(), lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vevxH_zefD94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, target in train_dl:\n",
        "            pred, mu, log_var = model(data)\n",
        "            loss = loss_func(mu, log_var, pred, target)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            average_valid_loss = torch.zeros(1)\n",
        "            l1_loss = torch.zeros(1)\n",
        "            num_batch = 0\n",
        "            for data, target in valid_dl:\n",
        "                pred, mu, log_var = model(data)\n",
        "                average_valid_loss += loss_func(mu, log_var, pred, target)\n",
        "                num_batch += 1\n",
        "                l1_loss += F.l1_loss(pred, target, reduction='sum')\n",
        "            average_valid_loss /= num_batch\n",
        "            l1_loss /= (bs * num_batch)\n",
        "            print(\"Epoch: \" + str(epoch) + \"  L1 + KL-divergence: \" + str(average_valid_loss) + \"  L1-loss: \" + str(l1_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APwqznr_fD9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "901KaiaRfD-D",
        "colab_type": "code",
        "outputId": "e3ea9056-bf1f-4ac5-8938-4c8865ef67e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(epochs, model_vae, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0  L1 + KL-divergence: tensor([75.4181])  L1-loss: tensor([145.2146])\n",
            "Epoch: 1  L1 + KL-divergence: tensor([72.6655])  L1-loss: tensor([139.6529])\n",
            "Epoch: 2  L1 + KL-divergence: tensor([73.8619])  L1-loss: tensor([142.0478])\n",
            "Epoch: 3  L1 + KL-divergence: tensor([73.2731])  L1-loss: tensor([140.8357])\n",
            "Epoch: 4  L1 + KL-divergence: tensor([74.8062])  L1-loss: tensor([143.9437])\n",
            "Epoch: 5  L1 + KL-divergence: tensor([79.0089])  L1-loss: tensor([152.3104])\n",
            "Epoch: 6  L1 + KL-divergence: tensor([76.7373])  L1-loss: tensor([147.7268])\n",
            "Epoch: 7  L1 + KL-divergence: tensor([77.2409])  L1-loss: tensor([148.6906])\n",
            "Epoch: 8  L1 + KL-divergence: tensor([78.3884])  L1-loss: tensor([151.0256])\n",
            "Epoch: 9  L1 + KL-divergence: tensor([72.1967])  L1-loss: tensor([138.6041])\n",
            "Epoch: 10  L1 + KL-divergence: tensor([78.0018])  L1-loss: tensor([150.2421])\n",
            "Epoch: 11  L1 + KL-divergence: tensor([73.6514])  L1-loss: tensor([141.4818])\n",
            "Epoch: 12  L1 + KL-divergence: tensor([76.2402])  L1-loss: tensor([146.6442])\n",
            "Epoch: 13  L1 + KL-divergence: tensor([77.9770])  L1-loss: tensor([150.1248])\n",
            "Epoch: 14  L1 + KL-divergence: tensor([74.0205])  L1-loss: tensor([142.2187])\n",
            "Epoch: 15  L1 + KL-divergence: tensor([78.4494])  L1-loss: tensor([151.0275])\n",
            "Epoch: 16  L1 + KL-divergence: tensor([75.6192])  L1-loss: tensor([145.3063])\n",
            "Epoch: 17  L1 + KL-divergence: tensor([74.1131])  L1-loss: tensor([142.3562])\n",
            "Epoch: 18  L1 + KL-divergence: tensor([83.6661])  L1-loss: tensor([161.4066])\n",
            "Epoch: 19  L1 + KL-divergence: tensor([92.9646])  L1-loss: tensor([180.0083])\n",
            "Epoch: 20  L1 + KL-divergence: tensor([74.2611])  L1-loss: tensor([142.5799])\n",
            "Epoch: 21  L1 + KL-divergence: tensor([75.1719])  L1-loss: tensor([144.4093])\n",
            "Epoch: 22  L1 + KL-divergence: tensor([73.8458])  L1-loss: tensor([141.7247])\n",
            "Epoch: 23  L1 + KL-divergence: tensor([74.9618])  L1-loss: tensor([143.9648])\n",
            "Epoch: 24  L1 + KL-divergence: tensor([75.7863])  L1-loss: tensor([145.5433])\n",
            "Epoch: 25  L1 + KL-divergence: tensor([87.9470])  L1-loss: tensor([169.8947])\n",
            "Epoch: 26  L1 + KL-divergence: tensor([79.6723])  L1-loss: tensor([153.3077])\n",
            "Epoch: 27  L1 + KL-divergence: tensor([76.0752])  L1-loss: tensor([146.0720])\n",
            "Epoch: 28  L1 + KL-divergence: tensor([72.1265])  L1-loss: tensor([138.1774])\n",
            "Epoch: 29  L1 + KL-divergence: tensor([72.1439])  L1-loss: tensor([138.1785])\n",
            "Epoch: 30  L1 + KL-divergence: tensor([73.5499])  L1-loss: tensor([141.0147])\n",
            "Epoch: 31  L1 + KL-divergence: tensor([79.9024])  L1-loss: tensor([153.7295])\n",
            "Epoch: 32  L1 + KL-divergence: tensor([73.4737])  L1-loss: tensor([140.8323])\n",
            "Epoch: 33  L1 + KL-divergence: tensor([77.1792])  L1-loss: tensor([148.2447])\n",
            "Epoch: 34  L1 + KL-divergence: tensor([73.7254])  L1-loss: tensor([141.2762])\n",
            "Epoch: 35  L1 + KL-divergence: tensor([75.2619])  L1-loss: tensor([144.3494])\n",
            "Epoch: 36  L1 + KL-divergence: tensor([74.8501])  L1-loss: tensor([143.4852])\n",
            "Epoch: 37  L1 + KL-divergence: tensor([74.0815])  L1-loss: tensor([141.9105])\n",
            "Epoch: 38  L1 + KL-divergence: tensor([76.3088])  L1-loss: tensor([146.3553])\n",
            "Epoch: 39  L1 + KL-divergence: tensor([73.5524])  L1-loss: tensor([140.8528])\n",
            "Epoch: 40  L1 + KL-divergence: tensor([75.1205])  L1-loss: tensor([144.0376])\n",
            "Epoch: 41  L1 + KL-divergence: tensor([87.7074])  L1-loss: tensor([169.1137])\n",
            "Epoch: 42  L1 + KL-divergence: tensor([72.6703])  L1-loss: tensor([139.0414])\n",
            "Epoch: 43  L1 + KL-divergence: tensor([72.5755])  L1-loss: tensor([138.8592])\n",
            "Epoch: 44  L1 + KL-divergence: tensor([73.5649])  L1-loss: tensor([140.8031])\n",
            "Epoch: 45  L1 + KL-divergence: tensor([79.2785])  L1-loss: tensor([152.2488])\n",
            "Epoch: 46  L1 + KL-divergence: tensor([76.4589])  L1-loss: tensor([146.5952])\n",
            "Epoch: 47  L1 + KL-divergence: tensor([75.6512])  L1-loss: tensor([144.9810])\n",
            "Epoch: 48  L1 + KL-divergence: tensor([78.9906])  L1-loss: tensor([151.6118])\n",
            "Epoch: 49  L1 + KL-divergence: tensor([76.4769])  L1-loss: tensor([146.5787])\n",
            "Epoch: 50  L1 + KL-divergence: tensor([86.9661])  L1-loss: tensor([167.5920])\n",
            "Epoch: 51  L1 + KL-divergence: tensor([84.6265])  L1-loss: tensor([162.8923])\n",
            "Epoch: 52  L1 + KL-divergence: tensor([73.0193])  L1-loss: tensor([139.6288])\n",
            "Epoch: 53  L1 + KL-divergence: tensor([75.4330])  L1-loss: tensor([144.4406])\n",
            "Epoch: 54  L1 + KL-divergence: tensor([71.5295])  L1-loss: tensor([136.6836])\n",
            "Epoch: 55  L1 + KL-divergence: tensor([79.9643])  L1-loss: tensor([153.5359])\n",
            "Epoch: 56  L1 + KL-divergence: tensor([84.1817])  L1-loss: tensor([161.9914])\n",
            "Epoch: 57  L1 + KL-divergence: tensor([88.5469])  L1-loss: tensor([170.6663])\n",
            "Epoch: 58  L1 + KL-divergence: tensor([74.5490])  L1-loss: tensor([142.6855])\n",
            "Epoch: 59  L1 + KL-divergence: tensor([72.7986])  L1-loss: tensor([139.1681])\n",
            "Epoch: 60  L1 + KL-divergence: tensor([71.7220])  L1-loss: tensor([137.0287])\n",
            "Epoch: 61  L1 + KL-divergence: tensor([76.6451])  L1-loss: tensor([146.8503])\n",
            "Epoch: 62  L1 + KL-divergence: tensor([79.4314])  L1-loss: tensor([152.4434])\n",
            "Epoch: 63  L1 + KL-divergence: tensor([73.7568])  L1-loss: tensor([141.0828])\n",
            "Epoch: 64  L1 + KL-divergence: tensor([77.1920])  L1-loss: tensor([147.9520])\n",
            "Epoch: 65  L1 + KL-divergence: tensor([71.5311])  L1-loss: tensor([136.6296])\n",
            "Epoch: 66  L1 + KL-divergence: tensor([79.7435])  L1-loss: tensor([153.0448])\n",
            "Epoch: 67  L1 + KL-divergence: tensor([77.6962])  L1-loss: tensor([148.9290])\n",
            "Epoch: 68  L1 + KL-divergence: tensor([85.3761])  L1-loss: tensor([164.2979])\n",
            "Epoch: 69  L1 + KL-divergence: tensor([75.1657])  L1-loss: tensor([143.9048])\n",
            "Epoch: 70  L1 + KL-divergence: tensor([74.3549])  L1-loss: tensor([142.2387])\n",
            "Epoch: 71  L1 + KL-divergence: tensor([75.2860])  L1-loss: tensor([144.1428])\n",
            "Epoch: 72  L1 + KL-divergence: tensor([82.4795])  L1-loss: tensor([158.4964])\n",
            "Epoch: 73  L1 + KL-divergence: tensor([81.7592])  L1-loss: tensor([157.0171])\n",
            "Epoch: 74  L1 + KL-divergence: tensor([74.8775])  L1-loss: tensor([143.2847])\n",
            "Epoch: 75  L1 + KL-divergence: tensor([76.4071])  L1-loss: tensor([146.3784])\n",
            "Epoch: 76  L1 + KL-divergence: tensor([71.4971])  L1-loss: tensor([136.5470])\n",
            "Epoch: 77  L1 + KL-divergence: tensor([83.0686])  L1-loss: tensor([159.5929])\n",
            "Epoch: 78  L1 + KL-divergence: tensor([73.4375])  L1-loss: tensor([140.3664])\n",
            "Epoch: 79  L1 + KL-divergence: tensor([78.2465])  L1-loss: tensor([149.9950])\n",
            "Epoch: 80  L1 + KL-divergence: tensor([74.4852])  L1-loss: tensor([142.4972])\n",
            "Epoch: 81  L1 + KL-divergence: tensor([73.7024])  L1-loss: tensor([140.8516])\n",
            "Epoch: 82  L1 + KL-divergence: tensor([73.5669])  L1-loss: tensor([140.6184])\n",
            "Epoch: 83  L1 + KL-divergence: tensor([76.6076])  L1-loss: tensor([146.7032])\n",
            "Epoch: 84  L1 + KL-divergence: tensor([83.1357])  L1-loss: tensor([159.7208])\n",
            "Epoch: 85  L1 + KL-divergence: tensor([73.5613])  L1-loss: tensor([140.6097])\n",
            "Epoch: 86  L1 + KL-divergence: tensor([86.1708])  L1-loss: tensor([165.8503])\n",
            "Epoch: 87  L1 + KL-divergence: tensor([78.4370])  L1-loss: tensor([150.4023])\n",
            "Epoch: 88  L1 + KL-divergence: tensor([74.1991])  L1-loss: tensor([141.8859])\n",
            "Epoch: 89  L1 + KL-divergence: tensor([75.6817])  L1-loss: tensor([144.8634])\n",
            "Epoch: 90  L1 + KL-divergence: tensor([79.1736])  L1-loss: tensor([151.7848])\n",
            "Epoch: 91  L1 + KL-divergence: tensor([86.0319])  L1-loss: tensor([165.4727])\n",
            "Epoch: 92  L1 + KL-divergence: tensor([75.5049])  L1-loss: tensor([144.4394])\n",
            "Epoch: 93  L1 + KL-divergence: tensor([79.5897])  L1-loss: tensor([152.6484])\n",
            "Epoch: 94  L1 + KL-divergence: tensor([84.6286])  L1-loss: tensor([162.7257])\n",
            "Epoch: 95  L1 + KL-divergence: tensor([71.8622])  L1-loss: tensor([137.2278])\n",
            "Epoch: 96  L1 + KL-divergence: tensor([72.9320])  L1-loss: tensor([139.3071])\n",
            "Epoch: 97  L1 + KL-divergence: tensor([79.7590])  L1-loss: tensor([152.9454])\n",
            "Epoch: 98  L1 + KL-divergence: tensor([76.4158])  L1-loss: tensor([146.2012])\n",
            "Epoch: 99  L1 + KL-divergence: tensor([74.7319])  L1-loss: tensor([142.8436])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr_bAB24fD-K",
        "colab_type": "code",
        "outputId": "a84b79b4-5257-4ce4-8dba-a5e44b22c91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "pyplot.imshow(x_valid[9].reshape((28, 28)), cmap=\"gray\")"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f50f1d40dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLv6C-k_iUcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result, mu, log_var = model_vae(valid_data[9].unsqueeze(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxos1wUid0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_result= result[0,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubTsOym-iqTB",
        "colab_type": "code",
        "outputId": "b2b401d0-dcbb-4e6b-b53e-a6fd655bb08c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "pyplot.imshow(x_result.cpu().detach().numpy(), cmap=\"gray\")"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f50f1ca0898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRKtPyIDCDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_vae.state_dict(), \"/content/gdrive/My Drive/Colab Notebooks/Modal_VAE/vae_mnist\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmFRxhrvLhxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}