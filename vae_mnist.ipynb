{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "vae_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB45F4XMfD7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2jzc_0LfKsG",
        "colab_type": "code",
        "outputId": "6fb99c83-9a24-43ee-9ebd-3ef48d57bb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ1Cx0wvfD8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((\"/content/gdrive/My Drive/Colab Notebooks/Modal_VAE/mnist/mnist.pkl.gz\"), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3tjkjnefD8g",
        "colab_type": "code",
        "outputId": "0b6788b3-1d72-473e-8a86-3883aa8f4e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "print(x_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA1K0lpJfD8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC87YpVzfD8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "train_data = torch.tensor(x_train, device=dev).reshape(train_size, 28, 28).unsqueeze(1)\n",
        "train_target = torch.tensor(y_train, device=dev)\n",
        "\n",
        "valid_size = x_valid.shape[0]\n",
        "valid_data = torch.tensor(x_valid, device=dev).reshape(valid_size, 28, 28).unsqueeze(1)\n",
        "valid_target = torch.tensor(y_valid, device=dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fS_ZS8XfD85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1qTbNjTfD9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = TensorDataset(train_data, train_data)\n",
        "valid_ds = TensorDataset(valid_data, valid_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Omyyz20fD9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, 2*bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt6LtCPJfD9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, channels, dim_h, dim_z):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "\n",
        "        #encoder\n",
        "        self.conv2d_encode1 = nn.Conv2d(1, 1, (2,2), stride=2, padding=0)\n",
        "        self.maxPool2d_encode1=nn.MaxPool2d((2,2), stride=2, padding=1, return_indices=True)\n",
        "        self.conv2d_encode2 = nn.Conv2d(1, 1, (2,2), stride=1, padding=0)\n",
        "        \n",
        "        #\n",
        "        self.p = nn.Linear(dim_h, dim_z)\n",
        "        \n",
        "        #decoder\n",
        "        self.convTrans2d_decode1 = nn.ConvTranspose2d(1, 1, (2,2), stride=2, padding=0)\n",
        "        self.bn_decode1 = nn.BatchNorm2d(1)\n",
        "        self.maxUnpool2d_decode = nn.MaxUnpool2d((2,2), stride=2)\n",
        "        self.bn_decode2 = nn.BatchNorm2d(1)\n",
        "        self.convTrans2d_decode2 = nn.ConvTranspose2d(1, 1, (3,3), stride=2, padding=0)\n",
        "        self.bn_decode3 = nn.BatchNorm2d(1)\n",
        "        self.p2 = nn.Linear(33*33, 28*28)\n",
        "\n",
        "    \n",
        "    def encode(self, in_data):\n",
        "\n",
        "        h = self.conv2d_encode1(in_data)\n",
        "        h = F.relu(h)\n",
        "        h, indices = self.maxPool2d_encode1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2d_encode2(h)\n",
        "        h = h.reshape(h.shape[0], -1)\n",
        "\n",
        "        #mu = self.p1(h)\n",
        "        #log_var = self.p2(h)\n",
        "        h = self.p(h)\n",
        "        mu, log_var = torch.split(h, 16, 1)\n",
        "        \n",
        "        #sampling and reparameterization for backprop\n",
        "        z = torch.rand(mu.shape, device = dev)\n",
        "        z = mu + torch.exp(log_var) * z\n",
        "        z = z.reshape(z.shape[0], 1, 4, 4)\n",
        "        return z, mu, log_var, indices\n",
        "    \n",
        "    def decode(self, h_data, indices):\n",
        "        z = self.convTrans2d_decode1(h_data)\n",
        "        z = self.bn_decode1(z)\n",
        "        z = F.relu(z)\n",
        "        z = self.maxUnpool2d_decode(z, indices)\n",
        "        z = self.bn_decode2(z)\n",
        "        z = F.relu(z)\n",
        "        z = self.convTrans2d_decode2(z)\n",
        "        z = self.bn_decode3(z)\n",
        "\n",
        "        z = z.reshape(z.shape[0], 33*33)\n",
        "        z = self.p2(z)\n",
        "        z = z.reshape(z.shape[0], 1, 28, 28)\n",
        "        return z\n",
        "                \n",
        "    def forward(self, in_data):\n",
        "        z, mu, log_var, indices = self.encode(in_data)\n",
        "\n",
        "        z = self.decode(z, indices)\n",
        "        return z, mu, log_var        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRFpi7HvfD9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vae = VAE(11, 49, 32).to(dev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ6YmOe9fD9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Kullback–Leibler divergence for N(mu, var^2) and N(0, I)\n",
        "def kl_divergence(mu, log_var):\n",
        "    return 0.5*( torch.sum( log_var.exp(), 1) + torch.sum(mu*mu, 1) - mu.shape[1] - torch.sum(log_var, 1) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEV3BCH4fD9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(MSE loss + Kullback–Leibler divergence) / batch\n",
        "def vae_loss(mu, log_var, pred, target):\n",
        "    bs = pred.shape[0]\n",
        "    kl_loss = kl_divergence(mu, log_var).mean()\n",
        "    l1_loss = F.l1_loss(pred, target, reduction = 'sum') / bs\n",
        "    return (kl_loss + l1_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNlxNc-nfD9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riOO5T7tfD9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = vae_loss\n",
        "opt = torch.optim.Adam(model_vae.parameters(), lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vevxH_zefD94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for data, target in train_dl:\n",
        "            pred, mu, log_var = model(data)\n",
        "            loss = loss_func(mu, log_var, pred, target)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            average_valid_loss = torch.zeros(1)\n",
        "            l1_loss = torch.zeros(1)\n",
        "            num_batch = 0\n",
        "            for data, target in valid_dl:\n",
        "                pred, mu, log_var = model(data)\n",
        "                average_valid_loss += loss_func(mu, log_var, pred, target)\n",
        "                num_batch += 1\n",
        "                l1_loss += F.l1_loss(pred, target, reduction='sum')\n",
        "            average_valid_loss /= num_batch\n",
        "            l1_loss /= (bs * num_batch)\n",
        "            print(\"Epoch: \" + str(epoch) + \"  L1 + KL-divergence: \" + str(average_valid_loss) + \"  L1-loss: \" + str(l1_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APwqznr_fD9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "901KaiaRfD-D",
        "colab_type": "code",
        "outputId": "a84f3560-33e8-49c1-8c18-886d78c02def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fit(epochs, model_vae, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0  L1 + KL-divergence: tensor([55.6121])  L1-loss: tensor([106.0940])\n",
            "Epoch: 1  L1 + KL-divergence: tensor([55.6147])  L1-loss: tensor([106.1145])\n",
            "Epoch: 2  L1 + KL-divergence: tensor([55.6998])  L1-loss: tensor([106.2770])\n",
            "Epoch: 3  L1 + KL-divergence: tensor([55.6275])  L1-loss: tensor([106.1371])\n",
            "Epoch: 4  L1 + KL-divergence: tensor([55.6425])  L1-loss: tensor([106.1500])\n",
            "Epoch: 5  L1 + KL-divergence: tensor([55.6587])  L1-loss: tensor([106.1820])\n",
            "Epoch: 6  L1 + KL-divergence: tensor([55.6245])  L1-loss: tensor([106.1184])\n",
            "Epoch: 7  L1 + KL-divergence: tensor([55.6215])  L1-loss: tensor([106.1274])\n",
            "Epoch: 8  L1 + KL-divergence: tensor([55.6354])  L1-loss: tensor([106.1308])\n",
            "Epoch: 9  L1 + KL-divergence: tensor([55.6238])  L1-loss: tensor([106.0897])\n",
            "Epoch: 10  L1 + KL-divergence: tensor([55.6029])  L1-loss: tensor([106.0571])\n",
            "Epoch: 11  L1 + KL-divergence: tensor([55.6264])  L1-loss: tensor([106.0957])\n",
            "Epoch: 12  L1 + KL-divergence: tensor([55.6443])  L1-loss: tensor([106.1349])\n",
            "Epoch: 13  L1 + KL-divergence: tensor([55.5822])  L1-loss: tensor([106.0019])\n",
            "Epoch: 14  L1 + KL-divergence: tensor([55.6301])  L1-loss: tensor([106.0896])\n",
            "Epoch: 15  L1 + KL-divergence: tensor([55.6039])  L1-loss: tensor([106.0347])\n",
            "Epoch: 16  L1 + KL-divergence: tensor([55.6251])  L1-loss: tensor([106.0854])\n",
            "Epoch: 17  L1 + KL-divergence: tensor([55.6333])  L1-loss: tensor([106.0968])\n",
            "Epoch: 18  L1 + KL-divergence: tensor([55.6634])  L1-loss: tensor([106.1704])\n",
            "Epoch: 19  L1 + KL-divergence: tensor([55.6203])  L1-loss: tensor([106.0929])\n",
            "Epoch: 20  L1 + KL-divergence: tensor([55.5808])  L1-loss: tensor([105.9831])\n",
            "Epoch: 21  L1 + KL-divergence: tensor([55.5694])  L1-loss: tensor([105.9771])\n",
            "Epoch: 22  L1 + KL-divergence: tensor([55.6229])  L1-loss: tensor([106.0712])\n",
            "Epoch: 23  L1 + KL-divergence: tensor([55.6398])  L1-loss: tensor([106.1003])\n",
            "Epoch: 24  L1 + KL-divergence: tensor([55.6485])  L1-loss: tensor([106.1271])\n",
            "Epoch: 25  L1 + KL-divergence: tensor([55.5987])  L1-loss: tensor([106.0011])\n",
            "Epoch: 26  L1 + KL-divergence: tensor([55.6316])  L1-loss: tensor([106.0880])\n",
            "Epoch: 27  L1 + KL-divergence: tensor([55.7048])  L1-loss: tensor([106.2290])\n",
            "Epoch: 28  L1 + KL-divergence: tensor([55.6041])  L1-loss: tensor([106.0278])\n",
            "Epoch: 29  L1 + KL-divergence: tensor([55.5984])  L1-loss: tensor([105.9811])\n",
            "Epoch: 30  L1 + KL-divergence: tensor([55.6287])  L1-loss: tensor([106.0744])\n",
            "Epoch: 31  L1 + KL-divergence: tensor([55.6125])  L1-loss: tensor([106.0426])\n",
            "Epoch: 32  L1 + KL-divergence: tensor([55.6208])  L1-loss: tensor([106.0344])\n",
            "Epoch: 33  L1 + KL-divergence: tensor([55.6103])  L1-loss: tensor([106.0176])\n",
            "Epoch: 34  L1 + KL-divergence: tensor([55.6007])  L1-loss: tensor([106.0132])\n",
            "Epoch: 35  L1 + KL-divergence: tensor([55.7659])  L1-loss: tensor([106.3264])\n",
            "Epoch: 36  L1 + KL-divergence: tensor([55.6986])  L1-loss: tensor([106.1936])\n",
            "Epoch: 37  L1 + KL-divergence: tensor([55.7539])  L1-loss: tensor([106.2931])\n",
            "Epoch: 38  L1 + KL-divergence: tensor([55.6500])  L1-loss: tensor([106.1004])\n",
            "Epoch: 39  L1 + KL-divergence: tensor([55.6384])  L1-loss: tensor([106.0995])\n",
            "Epoch: 40  L1 + KL-divergence: tensor([55.6659])  L1-loss: tensor([106.1412])\n",
            "Epoch: 41  L1 + KL-divergence: tensor([55.7118])  L1-loss: tensor([106.2030])\n",
            "Epoch: 42  L1 + KL-divergence: tensor([55.6176])  L1-loss: tensor([106.0193])\n",
            "Epoch: 43  L1 + KL-divergence: tensor([55.6867])  L1-loss: tensor([106.1767])\n",
            "Epoch: 44  L1 + KL-divergence: tensor([55.5948])  L1-loss: tensor([105.9781])\n",
            "Epoch: 45  L1 + KL-divergence: tensor([55.7249])  L1-loss: tensor([106.2443])\n",
            "Epoch: 46  L1 + KL-divergence: tensor([55.6044])  L1-loss: tensor([105.9906])\n",
            "Epoch: 47  L1 + KL-divergence: tensor([55.6079])  L1-loss: tensor([105.9872])\n",
            "Epoch: 48  L1 + KL-divergence: tensor([55.6657])  L1-loss: tensor([106.1172])\n",
            "Epoch: 49  L1 + KL-divergence: tensor([55.6068])  L1-loss: tensor([105.9955])\n",
            "Epoch: 50  L1 + KL-divergence: tensor([55.6129])  L1-loss: tensor([106.0044])\n",
            "Epoch: 51  L1 + KL-divergence: tensor([55.5879])  L1-loss: tensor([105.9552])\n",
            "Epoch: 52  L1 + KL-divergence: tensor([55.6075])  L1-loss: tensor([105.9716])\n",
            "Epoch: 53  L1 + KL-divergence: tensor([55.6346])  L1-loss: tensor([106.0538])\n",
            "Epoch: 54  L1 + KL-divergence: tensor([55.7224])  L1-loss: tensor([106.2153])\n",
            "Epoch: 55  L1 + KL-divergence: tensor([55.6386])  L1-loss: tensor([106.0574])\n",
            "Epoch: 56  L1 + KL-divergence: tensor([55.6159])  L1-loss: tensor([106.0013])\n",
            "Epoch: 57  L1 + KL-divergence: tensor([55.9160])  L1-loss: tensor([106.6015])\n",
            "Epoch: 58  L1 + KL-divergence: tensor([55.7039])  L1-loss: tensor([106.1669])\n",
            "Epoch: 59  L1 + KL-divergence: tensor([55.6586])  L1-loss: tensor([106.0842])\n",
            "Epoch: 60  L1 + KL-divergence: tensor([55.6244])  L1-loss: tensor([106.0162])\n",
            "Epoch: 61  L1 + KL-divergence: tensor([55.6564])  L1-loss: tensor([106.0658])\n",
            "Epoch: 62  L1 + KL-divergence: tensor([55.6947])  L1-loss: tensor([106.1274])\n",
            "Epoch: 63  L1 + KL-divergence: tensor([55.8990])  L1-loss: tensor([106.5743])\n",
            "Epoch: 64  L1 + KL-divergence: tensor([55.6602])  L1-loss: tensor([106.0955])\n",
            "Epoch: 65  L1 + KL-divergence: tensor([55.6431])  L1-loss: tensor([106.0327])\n",
            "Epoch: 66  L1 + KL-divergence: tensor([55.6089])  L1-loss: tensor([105.9815])\n",
            "Epoch: 67  L1 + KL-divergence: tensor([55.6435])  L1-loss: tensor([106.0565])\n",
            "Epoch: 68  L1 + KL-divergence: tensor([55.6309])  L1-loss: tensor([105.9934])\n",
            "Epoch: 69  L1 + KL-divergence: tensor([55.6877])  L1-loss: tensor([106.1313])\n",
            "Epoch: 70  L1 + KL-divergence: tensor([55.7735])  L1-loss: tensor([106.2954])\n",
            "Epoch: 71  L1 + KL-divergence: tensor([55.6866])  L1-loss: tensor([106.1227])\n",
            "Epoch: 72  L1 + KL-divergence: tensor([55.6495])  L1-loss: tensor([106.0474])\n",
            "Epoch: 73  L1 + KL-divergence: tensor([55.6206])  L1-loss: tensor([105.9832])\n",
            "Epoch: 74  L1 + KL-divergence: tensor([55.7288])  L1-loss: tensor([106.1805])\n",
            "Epoch: 75  L1 + KL-divergence: tensor([55.6848])  L1-loss: tensor([106.0953])\n",
            "Epoch: 76  L1 + KL-divergence: tensor([55.7213])  L1-loss: tensor([106.1900])\n",
            "Epoch: 77  L1 + KL-divergence: tensor([55.6042])  L1-loss: tensor([105.9393])\n",
            "Epoch: 78  L1 + KL-divergence: tensor([55.6150])  L1-loss: tensor([105.9421])\n",
            "Epoch: 79  L1 + KL-divergence: tensor([55.6157])  L1-loss: tensor([105.9841])\n",
            "Epoch: 80  L1 + KL-divergence: tensor([55.6489])  L1-loss: tensor([106.0450])\n",
            "Epoch: 81  L1 + KL-divergence: tensor([55.6276])  L1-loss: tensor([105.9883])\n",
            "Epoch: 82  L1 + KL-divergence: tensor([55.6843])  L1-loss: tensor([106.0671])\n",
            "Epoch: 83  L1 + KL-divergence: tensor([55.6227])  L1-loss: tensor([105.9727])\n",
            "Epoch: 84  L1 + KL-divergence: tensor([55.6022])  L1-loss: tensor([105.9442])\n",
            "Epoch: 85  L1 + KL-divergence: tensor([55.6657])  L1-loss: tensor([106.0485])\n",
            "Epoch: 86  L1 + KL-divergence: tensor([55.6032])  L1-loss: tensor([105.9186])\n",
            "Epoch: 87  L1 + KL-divergence: tensor([55.6556])  L1-loss: tensor([106.0261])\n",
            "Epoch: 88  L1 + KL-divergence: tensor([55.7898])  L1-loss: tensor([106.2990])\n",
            "Epoch: 89  L1 + KL-divergence: tensor([55.7160])  L1-loss: tensor([106.1467])\n",
            "Epoch: 90  L1 + KL-divergence: tensor([55.6061])  L1-loss: tensor([105.9364])\n",
            "Epoch: 91  L1 + KL-divergence: tensor([55.6447])  L1-loss: tensor([106.0315])\n",
            "Epoch: 92  L1 + KL-divergence: tensor([55.5900])  L1-loss: tensor([105.9294])\n",
            "Epoch: 93  L1 + KL-divergence: tensor([55.6897])  L1-loss: tensor([106.0921])\n",
            "Epoch: 94  L1 + KL-divergence: tensor([55.6573])  L1-loss: tensor([106.0408])\n",
            "Epoch: 95  L1 + KL-divergence: tensor([55.6122])  L1-loss: tensor([105.9208])\n",
            "Epoch: 96  L1 + KL-divergence: tensor([55.6404])  L1-loss: tensor([105.9917])\n",
            "Epoch: 97  L1 + KL-divergence: tensor([55.6760])  L1-loss: tensor([106.0589])\n",
            "Epoch: 98  L1 + KL-divergence: tensor([55.6465])  L1-loss: tensor([105.9793])\n",
            "Epoch: 99  L1 + KL-divergence: tensor([55.5902])  L1-loss: tensor([105.8844])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr_bAB24fD-K",
        "colab_type": "code",
        "outputId": "43835d90-2793-47a4-a5b8-ec475edd0bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "pyplot.imshow(x_valid[7404].reshape((28, 28)), cmap=\"gray\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7feae453c6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAOJElEQVR4nO3db4xV9Z3H8c933WIMxYR/SwYLWqrGNCZON6NZMsa4muKfkEBjbJgHho1Nxgc1VrPJSroPQDdNdHe76iMMtfzZDVIboWCajXSW1GXxQQUN4jgCugqWcYTgGLHR2AW++2AOu1OZ8zvjOffcc4fv+5VM5s753nPONzd8OOee3z33Z+4uABe+P2u6AQDtQdiBIAg7EARhB4Ig7EAQf97OnZkZl/6Bmrm7TbS80pHdzG43s0Nm9o6ZraqyLQD1srLj7GZ2kaTDkr4r6ZikvZL63H0osQ5HdqBmdRzZb5D0jru/6+5/lPQLScsqbA9AjaqE/TJJvx/397Fs2Z8ws34z22dm+yrsC0BFtV+gc/d1ktZJnMYDTapyZB+WtGDc39/IlgHoQFXCvlfSVWb2TTObJmmFpBda0xaAVit9Gu/up83sfkk7JV0kab27v9myzgC0VOmht1I74z07ULtaPlQDYOog7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCItk7ZjHpcffXVubUdO3Yk173mmmuS9T179iTrTz75ZLJ+6NCh3Nrg4GByXbQWR3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJZXC8AL7/8cm5t8eLFbezkfKdOncqtPffcc8l1V61alax//PHHpXq60OXN4lrpQzVmdkTSp5LOSDrt7j1VtgegPq34BN1fu/vJFmwHQI14zw4EUTXsLuk3ZvaqmfVP9AQz6zezfWa2r+K+AFRQ9TT+RncfNrO/kDRgZgfdfff4J7j7OknrJC7QAU2qdGR39+Hs9wlJv5J0QyuaAtB6pcNuZtPNbMa5x5KWSOKeRaBDlR5nN7NFGjuaS2NvB551958UrMNpfAm9vb3J+u7du3NrZhMOuU4JmzdvTtbvueeeNnUytbR8nN3d35V0XemOALQVQ29AEIQdCIKwA0EQdiAIwg4EwVdJTwF33XVXsl5leG3v3r3J+gMPPJCsDw0NJes9Pfk3Qq5duza57vLly5P1vr6+ZH3Lli3JejQc2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCL5KugPMnDkzWT948GCyPnfu3Nza0aNHk+tef/31yfrJk/V9l+jKlSuT9Q0bNiTrx44dS9YXLlz4lXu6EOTd4sqRHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeC4H72DtDd3Z2sp8bRizzzzDPJep3j6EVeeumlSuvPnz8/WX/kkUdya6tXr66076mIIzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBMH97B3g4osvTtaL7tuePXt2bm3Hjh3JdR9//PFkvciBAweS9c8++yy3dvnllyfXfe+990r1dM7o6Ghubc6cOZW23clK389uZuvN7ISZDY5bNsvMBszs7ex3+tsXADRuMqfxGyXd/qVlqyTtcverJO3K/gbQwQrD7u67JX35fGiZpE3Z402S0vP0AGhc2c/Gz3P3kezxh5Lm5T3RzPol9ZfcD4AWqXwjjLt76sKbu6+TtE7iAh3QpLJDb8fNrEuSst8nWtcSgDqUDfsLks59D/BKSenxHQCNKxxnN7Mtkm6WNEfScUmrJW2X9EtJCyUdlfR9d88f1Pz/bXEaX0LRPen33ntvmzo538jISLKeGusu+rd37bXXluppMvuOOM5e+J7d3fNmvL+1UkcA2oqPywJBEHYgCMIOBEHYgSAIOxAEXyU9BVx55ZVNt5Crq6urUr2Kolt/H3roodr2PRVxZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIBhn7wBLlixJ1nt7e0tv+/3330/WFy5cWHrbTdu+fXuyvnXr1jZ1MjVwZAeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIJiyuQ2mT5+erA8NDSXrCxYsSNb37NmTW1u6dGly3YcffjhZv/XW9JcIv/jii8l6asrmoq+hfvrpp5P1zz//PFkfGBjIrfX15X1p8tRXespmABcGwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH2Nii6X71orLrIHXfckVvbuXNnpW03acWKFcn6s88+m6yfPn06t3bfffcl192wYUOy3slKj7Ob2XozO2Fmg+OWrTGzYTPbn/3c2cpmAbTeZE7jN0q6fYLlT7h7d/bz761tC0CrFYbd3XdLGm1DLwBqVOUC3f1mdiA7zZ+Z9yQz6zezfWa2r8K+AFRUNuxrJX1LUrekEUk/zXuiu69z9x537ym5LwAtUCrs7n7c3c+4+1lJP5N0Q2vbAtBqpcJuZuPn4f2epMG85wLoDIXfG29mWyTdLGmOmR2TtFrSzWbWLcklHZGUHrRErWbMmNF0C7XYtm1bsr5///5kvbu7O7e2ePHi5LpTeZw9T2HY3X2iu/x/XkMvAGrEx2WBIAg7EARhB4Ig7EAQhB0Igimb2+CWW26pdfuXXHJJrdtvyrRp05L1Sy+9tE2dXBg4sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzt8Hrr79e6/Znz55d6/brMnfu3GR948aNyfqiRYtK7/uLL74ove5UxZEdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4JgnL0NPvroo1q3X3Tfd5Pmz5+fW9u+fXty3Z6eapMIjYyM5NZWr15dadtTEUd2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQjC3L19OzNr3846SNH95ocPH07WZ86cmay/8sorubWbbropue6ZM2eS9a6urmT97rvvTtbXrFmTWyuaavrs2bPJ+gcffJCsp6ZsHh0dTa47lbm7TbS88MhuZgvM7LdmNmRmb5rZj7Lls8xswMzezn6n/0UCaNRkTuNPS/pbd/+2pL+S9EMz+7akVZJ2uftVknZlfwPoUIVhd/cRd38te/yppLckXSZpmaRN2dM2SVpeV5MAqvtKn403syskfUfS7yTNc/dzHz7+UNK8nHX6JfWXbxFAK0z6aryZfV3SVkkPuvup8TUfu8o34cU3d1/n7j3uXu2uBgCVTCrsZvY1jQV9s7tvyxYfN7OurN4l6UQ9LQJohcKhNzMzjb0nH3X3B8ct/ydJH7n7Y2a2StIsd/+7gm2FHHor0tfXl6xv3ry59LYPHjyYrBfdftvb21t630U++eSTZP3RRx9N1p944olWtnPByBt6m8x79l5J90h6w8z2Z8t+LOkxSb80sx9IOirp+61oFEA9CsPu7nskTfg/haRbW9sOgLrwcVkgCMIOBEHYgSAIOxAEYQeC4BbXDjBnzpxkfWBgIFm/7rrrWtlOSw0PD+fWbrvttuS6Q0NDrW4nhNK3uAK4MBB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs08BRePw69evz60tXbq00r4HBweT9eeffz5Zf+qpp3JrRfezoxzG2YHgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZgQsM4+xAcIQdCIKwA0EQdiAIwg4EQdiBIAg7EERh2M1sgZn91syGzOxNM/tRtnyNmQ2b2f7s58762wVQVuGHasysS1KXu79mZjMkvSppucbmY/+Du//zpHfGh2qA2uV9qGYy87OPSBrJHn9qZm9Juqy17QGo21d6z25mV0j6jqTfZYvuN7MDZrbezGbmrNNvZvvMbF+lTgFUMunPxpvZ1yX9p6SfuPs2M5sn6aQkl/QPGjvVv7dgG5zGAzXLO42fVNjN7GuSfi1pp7v/ywT1KyT92t2vLdgOYQdqVvpGGDMzST+X9Nb4oGcX7s75nqT015ACaNRkrsbfKOm/JL0h6Wy2+MeS+iR1a+w0/oik+7KLealtcWQHalbpNL5VCDtQP+5nB4Ij7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFH4hZMtdlLS0XF/z8mWdaJO7a1T+5LoraxW9nZ5XqGt97Oft3Ozfe7e01gDCZ3aW6f2JdFbWe3qjdN4IAjCDgTRdNjXNbz/lE7trVP7kuitrLb01uh7dgDt0/SRHUCbEHYgiEbCbma3m9khM3vHzFY10UMeMztiZm9k01A3Oj9dNofeCTMbHLdslpkNmNnb2e8J59hrqLeOmMY7Mc14o69d09Oft/09u5ldJOmwpO9KOiZpr6Q+dx9qayM5zOyIpB53b/wDGGZ2k6Q/SPrXc1Nrmdk/Shp198ey/yhnuvvDHdLbGn3Fabxr6i1vmvG/UYOvXSunPy+jiSP7DZLecfd33f2Pkn4haVkDfXQ8d98tafRLi5dJ2pQ93qSxfyxtl9NbR3D3EXd/LXv8qaRz04w3+tol+mqLJsJ+maTfj/v7mDprvneX9Bsze9XM+ptuZgLzxk2z9aGkeU02M4HCabzb6UvTjHfMa1dm+vOquEB3vhvd/S8l3SHph9npakfysfdgnTR2ulbStzQ2B+CIpJ822Uw2zfhWSQ+6+6nxtSZfuwn6asvr1kTYhyUtGPf3N7JlHcHdh7PfJyT9SmNvOzrJ8XMz6Ga/TzTcz/9x9+Pufsbdz0r6mRp87bJpxrdK2uzu27LFjb92E/XVrtetibDvlXSVmX3TzKZJWiHphQb6OI+ZTc8unMjMpktaos6bivoFSSuzxysl7Wiwlz/RKdN4500zroZfu8anP3f3tv9IulNjV+T/W9LfN9FDTl+LJL2e/bzZdG+StmjstO5/NHZt4weSZkvaJeltSf8haVYH9fZvGpva+4DGgtXVUG83auwU/YCk/dnPnU2/dom+2vK68XFZIAgu0AFBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEP8LggmLy3nimycAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLv6C-k_iUcJ",
        "colab_type": "code",
        "outputId": "b3174025-c36e-4f36-ff2f-568a9dd82516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "result, mu, log_var = model_vae(valid_data[7404].unsqueeze(0))\n",
        "x_result= result[0,0]\n",
        "pyplot.imshow(x_result.cpu().detach().numpy(), cmap=\"gray\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7feae43197b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETRKtPyIDCDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_vae.state_dict(), \"/content/gdrive/My Drive/Colab Notebooks/Modal_VAE/vae_mnist2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF_d1iIy0IGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}